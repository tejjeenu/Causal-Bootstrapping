{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbcd0803",
   "metadata": {},
   "source": [
    "\n",
    "# Confounded vs deconfounded model comparison\n",
    "\n",
    "Train multiple classifiers on a confounded dataset and several pre-generated deconfounded datasets (e.g., backdoor, frontdoor, truncated factorisation). Compare their predictive metrics on a shared observational hold-out and on each deconfounded hold-out.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2665524c",
   "metadata": {},
   "source": [
    "\n",
    "**Workflow**\n",
    "1. Load confounded CSV and multiple deconfounded CSVs (already generated; no bootstrap here).\n",
    "2. Align feature columns common to all datasets and split each into train/test.\n",
    "3. Fit a set of common models on each training set.\n",
    "4. Evaluate on the same confounded hold-out to see how deconfounding affects generalization to observational data.\n",
    "5. Also evaluate on each deconfounded hold-out for interventional-like performance.\n",
    "\n",
    "> Set DECONFOUNDED_DATASETS below to your deconfounded files (same schema + target).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbb259c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    roc_auc_score,\n",
    "    average_precision_score,\n",
    "    brier_score_loss,\n",
    "    log_loss,\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.base import clone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c774b322",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Paths & columns ===\n",
    "CONFOUNDED_PATH = 'heart_disease_preprocessed.csv'\n",
    "DECONFOUNDED_DATASETS = [\n",
    "    {'name': 'Backdoor', 'path': 'heart_disease_deconf_backdoor.csv'},\n",
    "    {'name': 'Frontdoor', 'path': 'heart_disease_deconf_frontdoor.csv'},\n",
    "    {'name': 'TruncatedFactorisation', 'path': 'heart_disease_deconf_truncated.csv'},\n",
    "]\n",
    "\n",
    "TARGET = 'heartdiseasepresence'\n",
    "TEST_SIZE = 0.3\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "assert Path(CONFOUNDED_PATH).exists(), f\"Confounded file not found: {CONFOUNDED_PATH}\"\n",
    "for ds in DECONFOUNDED_DATASETS:\n",
    "    assert Path(ds['path']).exists(), f\"Deconfounded file not found: {ds['path']}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0f0881",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # Load datasets\n",
    "df_conf = pd.read_csv(CONFOUNDED_PATH)\n",
    "deconf_dfs = {}\n",
    "for ds in DECONFOUNDED_DATASETS:\n",
    "    deconf_dfs[ds['name']] = pd.read_csv(ds['path'])\n",
    "\n",
    "    # Align columns across all datasets (intersection to ensure comparability)\n",
    "common_cols = set(df_conf.columns)\n",
    "for name, df in deconf_dfs.items():\n",
    "    common_cols = common_cols.intersection(set(df.columns))\n",
    "assert TARGET in common_cols, f\"Target '{TARGET}' must exist in all datasets\"\n",
    "\n",
    "feature_cols = sorted([c for c in common_cols if c != TARGET])\n",
    "\n",
    "df_conf = df_conf[feature_cols + [TARGET]]\n",
    "for name in deconf_dfs:\n",
    "    deconf_dfs[name] = deconf_dfs[name][feature_cols + [TARGET]]\n",
    "\n",
    "print('Common features:', len(feature_cols))\n",
    "print('Confounded shape:', df_conf.shape)\n",
    "for name, df in deconf_dfs.items():\n",
    "    print(f\"Deconfounded ({name}) shape: {df.shape}\")\n",
    "\n",
    "print('Confounded target balance:', df_conf[TARGET].value_counts())\n",
    "for name, df in deconf_dfs.items():\n",
    "    print(f\"Deconfounded ({name}) target balance:\", df[TARGET].value_counts())\n",
    "\n",
    "df_conf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39eb8c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train/test splits for each dataset\n",
    "splits = {\n",
    "    'Confounded': {\n",
    "        'train': None,\n",
    "        'test': None,\n",
    "        'label': 'Confounded (observational)'\n",
    "    }\n",
    "}\n",
    "\n",
    "conf_train, conf_test = train_test_split(\n",
    "    df_conf, test_size=TEST_SIZE, random_state=RANDOM_SEED, stratify=df_conf[TARGET]\n",
    ")\n",
    "splits['Confounded']['train'] = conf_train\n",
    "splits['Confounded']['test'] = conf_test\n",
    "\n",
    "for name, df in deconf_dfs.items():\n",
    "    train_df, test_df = train_test_split(\n",
    "        df, test_size=TEST_SIZE, random_state=RANDOM_SEED, stratify=df[TARGET]\n",
    "    )\n",
    "    splits[name] = {'train': train_df, 'test': test_df, 'label': f'Deconfounded ({name})'}\n",
    "\n",
    "for name, split in splits.items():\n",
    "    print(name, 'train/test sizes:', len(split['train']), len(split['test']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9dd7f3",
   "metadata": {},
   "source": [
    "\n",
    "### Models and evaluation helpers\n",
    "\n",
    "Metrics: Accuracy, ROC AUC, PR AUC (average precision), Brier score, and log loss.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312e4175",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# based on whatever hyperparameter worked well evaluated based on HPO on confounded data\n",
    "\n",
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(max_iter=2000, solver='liblinear', random_state=RANDOM_SEED),\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=300, random_state=RANDOM_SEED),\n",
    "    'GradientBoosting': GradientBoostingClassifier(random_state=RANDOM_SEED),\n",
    "    'SVC_RBF': SVC(probability=True, kernel='rbf', C=2.0, gamma='scale', random_state=RANDOM_SEED),\n",
    "}\n",
    "\n",
    "def get_probas(model, X):\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        return model.predict_proba(X)[:, 1]\n",
    "    if hasattr(model, 'decision_function'):\n",
    "        scores = model.decision_function(X)\n",
    "        return 1 / (1 + np.exp(-scores))\n",
    "    raise ValueError('Model does not support probability-like outputs')\n",
    "\n",
    "def evaluate_model(model, X_train, y_train, X_eval, y_eval):\n",
    "    fitted = clone(model)\n",
    "    fitted.fit(X_train, y_train)\n",
    "    preds = fitted.predict(X_eval)\n",
    "    probas = get_probas(fitted, X_eval)\n",
    "    return {\n",
    "        'accuracy': accuracy_score(y_eval, preds),\n",
    "        'roc_auc': roc_auc_score(y_eval, probas),\n",
    "        'pr_auc': average_precision_score(y_eval, probas),\n",
    "        'brier': brier_score_loss(y_eval, probas),\n",
    "        'log_loss': log_loss(y_eval, probas),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5d69f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate all train/eval combinations\n",
    "results = []\n",
    "\n",
    "# Evaluation sets: always include the confounded test, plus each deconfounded test\n",
    "eval_sets = [('Confounded', splits['Confounded']['test'])]\n",
    "for name, split in splits.items():\n",
    "    if name == 'Confounded':\n",
    "        continue\n",
    "    eval_sets.append((name, split['test']))\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    for train_name, split in splits.items():\n",
    "        X_train = split['train'][feature_cols]\n",
    "        y_train = split['train'][TARGET]\n",
    "\n",
    "        for eval_name, eval_df in eval_sets:\n",
    "            X_eval = eval_df[feature_cols]\n",
    "            y_eval = eval_df[TARGET]\n",
    "            metrics = evaluate_model(model, X_train, y_train, X_eval, y_eval)\n",
    "            metrics.update({\n",
    "                'model': model_name,\n",
    "                'training_data': splits[train_name]['label'],\n",
    "                'evaluation': 'Confounded test' if eval_name == 'Confounded' else f'Deconfounded test ({eval_name})'\n",
    "            })\n",
    "            results.append(metrics)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75d4d54",
   "metadata": {},
   "source": [
    "\n",
    "### Combined, tidy comparison table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7373ce30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tidy(df):\n",
    "    cols = ['model', 'training_data', 'evaluation', 'accuracy', 'roc_auc', 'pr_auc', 'brier', 'log_loss']\n",
    "    return df[cols].sort_values(['evaluation', 'model', 'training_data']).reset_index(drop=True)\n",
    "\n",
    "tidy(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce227486",
   "metadata": {},
   "source": [
    "\n",
    "### Visualize observational (confounded) test accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65999261",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plot_df = results_df[results_df['evaluation'] == 'Confounded test'].copy()\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "\n",
    "train_labels = plot_df['training_data'].unique()\n",
    "train_labels_sorted = sorted(train_labels)\n",
    "x_pos = np.arange(len(train_labels_sorted))\n",
    "\n",
    "width = 0.15\n",
    "for idx, model_name in enumerate(sorted(plot_df['model'].unique())):\n",
    "    subset = plot_df[plot_df['model'] == model_name].set_index('training_data').loc[train_labels_sorted]\n",
    "    bars = ax.bar(x_pos + idx * width, subset['accuracy'], width=width, label=model_name)\n",
    "    for bar in bars:\n",
    "        ax.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.005, f\"{bar.get_height():.3f}\",\n",
    "                ha='center', va='bottom', fontsize=7)\n",
    "\n",
    "ax.set_xticks(x_pos + width * (len(plot_df['model'].unique()) - 1) / 2)\n",
    "ax.set_xticklabels(train_labels_sorted, rotation=15, ha='right')\n",
    "ax.set_ylabel('Accuracy on confounded test')\n",
    "ax.set_ylim(0, 1)\n",
    "ax.legend(title='Model')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
