{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a98137ec",
   "metadata": {},
   "source": [
    "# Truncated factorization causal bootstrapping (Algorithm 3)\n",
    "\n",
    "This notebook implements **Algorithm 3** from *Causal bootstrapping* (Little & Badawy, 2020).  \n",
    "It applies when **all variables are observed** and the causal graph is known, so that truncated factorization can be used.\n",
    "\n",
    "Algorithm 3 weights (paper):\n",
    "- Let \\(P(X)\\) be parents of effect variable(s) \\(X\\)\n",
    "- Let \\(E = P(X) \\setminus \\{Y\\}\\)\n",
    "\\[\n",
    "\\bar w_i = \\frac{\\prod_{v\\in E} \\hat p(v_i\\mid P(v) \\text{ with } Y=y^*)}{\\hat p(P(X)=p_i \\text{ with } Y=y^*)}\n",
    "\\]\n",
    "\\[\n",
    "w_i = \\frac{1}{N} K[y_i-y^*] \\bar w_i \\quad (\\text{if } Y\\in P(X))\n",
    "\\]\n",
    "\n",
    "Key reference: Algorithm 3 and Eq. (7)-(8), plus Section 2.5 in the paper. fileciteturn0file0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d9c539",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "def _ensure_2d(arr):\n",
    "    arr = np.asarray(arr)\n",
    "    if arr.ndim == 1:\n",
    "        arr = arr.reshape(-1, 1)\n",
    "    return arr\n",
    "\n",
    "def gaussian_kernel_matrix(A, B=None, bandwidth=1.0):\n",
    "    \"\"\"\n",
    "    Gaussian/RBF kernel matrix: K_ij = exp(-0.5 * ||a_i - b_j||^2 / h^2)\n",
    "    A: (n,d), B: (m,d)\n",
    "    \"\"\"\n",
    "    A = _ensure_2d(A)\n",
    "    if B is None:\n",
    "        B = A\n",
    "    else:\n",
    "        B = _ensure_2d(B)\n",
    "    dists = cdist(A, B, metric=\"euclidean\")\n",
    "    return np.exp(-0.5 * (dists / float(bandwidth)) ** 2)\n",
    "\n",
    "def kernel_y_vector(y_data, y_star, *, discrete=True, bandwidth_y=1.0):\n",
    "    \"\"\"\n",
    "    K[y_i - y*] used in the paper.\n",
    "    - discrete=True -> Kronecker delta (1 if equal else 0)\n",
    "    - discrete=False -> Gaussian kernel on (y_i - y*)\n",
    "    \"\"\"\n",
    "    y_data = np.asarray(y_data)\n",
    "    if discrete:\n",
    "        return (y_data == y_star).astype(float)\n",
    "    return np.exp(-0.5 * ((y_data - y_star) / float(bandwidth_y)) ** 2)\n",
    "\n",
    "def phat_y_given_S(y_data, S_data, y_star, *, discrete_y=True, bandwidth_S=1.0, bandwidth_y=1.0, eps=1e-12):\n",
    "    \"\"\"\n",
    "    Nonparametric estimate of p_hat(y* | S_i) for each i, using kernel regression:\n",
    "      p_hat(y*|S_i) = sum_j K_S(S_i, S_j) * K_Y(y_j, y*) / sum_j K_S(S_i, S_j)\n",
    "    Returns: (N,) vector over i.\n",
    "    \"\"\"\n",
    "    K_S = gaussian_kernel_matrix(S_data, bandwidth=bandwidth_S)  # (N,N)\n",
    "    K_Y = kernel_y_vector(y_data, y_star, discrete=discrete_y, bandwidth_y=bandwidth_y)  # (N,)\n",
    "    numer = K_S @ K_Y\n",
    "    denom = K_S.sum(axis=1)\n",
    "    return numer / np.maximum(denom, eps)\n",
    "\n",
    "def phat_z_given_y(z_data, y_data, *, bandwidth_z=1.0, eps=1e-12):\n",
    "    \"\"\"\n",
    "    For front-door (Algorithm 2): estimate p_hat(z_i | y=v) for all i and each discrete y=v.\n",
    "    KDE on z within each y-group:\n",
    "      p_hat(z_i | y=v) ∝ (1/N_v) * sum_{j:y_j=v} K_z(z_i, z_j)\n",
    "    Returns: dict mapping y_value -> (N,) vector, entry i is p_hat(z_i | y_value)\n",
    "    \"\"\"\n",
    "    z = _ensure_2d(z_data)\n",
    "    y = np.asarray(y_data)\n",
    "    y_vals = np.unique(y)\n",
    "\n",
    "    Kzz = gaussian_kernel_matrix(z, bandwidth=bandwidth_z)  # (N,N)\n",
    "    phat = {}\n",
    "    for v in y_vals:\n",
    "        mask = (y == v)\n",
    "        Nv = int(mask.sum())\n",
    "        if Nv == 0:\n",
    "            phat[v] = np.full(len(y), eps)\n",
    "            continue\n",
    "        numer = Kzz[:, mask].sum(axis=1) / float(Nv)\n",
    "        phat[v] = np.maximum(numer, eps)\n",
    "    return phat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec710709",
   "metadata": {},
   "source": [
    "## Provide the causal graph inputs\n",
    "\n",
    "You must specify:\n",
    "\n",
    "- `y_col`: intervention variable **Y** (usually your target label)\n",
    "- `x_cols`: features **X** you want to sample (used only for output; the weighting uses `x_parents`)\n",
    "- `x_parents`: the parent set **P(X)** used in the truncated factorization formula (a list of column names).\n",
    "  - **Important:** include `y_col` in `x_parents` if Y is a parent of X in your graph.\n",
    "- `parents`: a dictionary mapping each variable name `v` in `E` to its parent list `P(v)` (may include `y_col`).\n",
    "\n",
    "Assumptions:\n",
    "- Variables are treated as continuous for kernels unless included in `discrete_vars`.\n",
    "- This is a *nonparametric* estimator intended to mirror the paper's RKHS/KDE simplification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2568fae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- USER INPUTS ---\n",
    "df = pd.read_csv(\"heart_disease_preprocessed.csv\")  # change if needed\n",
    "\n",
    "y_col = \"heartdiseasepresence\"\n",
    "\n",
    "# Example (EDIT to match your causal DAG):\n",
    "# Suppose the feature block X depends on Y and some observed covariates E.\n",
    "x_cols = [c for c in df.columns if c != y_col]\n",
    "\n",
    "# Parents of the (vector) feature block X in your DAG:\n",
    "x_parents = [y_col, \"age\", \"sex_Female\", \"sex_Male\"]  # EDIT: P(X) in your graph\n",
    "\n",
    "# E = P(X) \\ {Y}:\n",
    "E_vars = [v for v in x_parents if v != y_col]\n",
    "\n",
    "# Parent sets for each v in E (EDIT to match your graph).\n",
    "# If a v has no parents, use [].\n",
    "parents = {\n",
    "    \"age\": [],\n",
    "    \"sex_Female\": [],\n",
    "    \"sex_Male\": [],\n",
    "}\n",
    "\n",
    "# Kernel settings\n",
    "discrete_vars = {y_col, \"sex_Female\", \"sex_Male\"}  # treat these with Kronecker delta\n",
    "bandwidth = 1.0  # shared bandwidth for continuous kernels\n",
    "\n",
    "random_seed = 0\n",
    "\n",
    "print(\"y_col:\", y_col)\n",
    "print(\"x_parents:\", x_parents)\n",
    "print(\"E_vars:\", E_vars)\n",
    "print(\"parents(v):\", parents)\n",
    "print(\"N:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436f144e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _phat_joint(query, data, *, bandwidth=1.0, eps=1e-12):\n",
    "    \"\"\"Unnormalized KDE joint density at query points: p_hat(query) ∝ (1/N) sum_j K(query, data_j).\"\"\"\n",
    "    K = gaussian_kernel_matrix(query, B=data, bandwidth=bandwidth)  # (Q,N)\n",
    "    return np.maximum(K.mean(axis=1), eps)\n",
    "\n",
    "def _kernel_target_matrix(target_data, query_targets, *, discrete=False, bandwidth=1.0):\n",
    "    \"\"\"Matrix Ky[q,j] = K(query_targets[q] - target_data[j]).\"\"\"\n",
    "    target_data = np.asarray(target_data)\n",
    "    qt = np.asarray(query_targets)\n",
    "    if qt.ndim == 0:\n",
    "        qt = qt.reshape(1)\n",
    "    if discrete:\n",
    "        return (qt[:, None] == target_data[None, :]).astype(float)\n",
    "    return np.exp(-0.5 * ((qt[:, None] - target_data[None, :]) / float(bandwidth)) ** 2)\n",
    "\n",
    "def _phat_conditional(target_data, parent_data, *, query_targets, query_parents,\n",
    "                      target_discrete=False, bandwidth_parent=1.0, bandwidth_target=1.0, eps=1e-12):\n",
    "    \"\"\"Kernel regression estimate of p_hat(target=query_targets | parents=query_parents).\n",
    "\n",
    "    Vectorized over Q queries (typically Q=N).\n",
    "    \"\"\"\n",
    "    parent_data = _ensure_2d(parent_data)\n",
    "    query_parents = _ensure_2d(query_parents)\n",
    "\n",
    "    # K(parents): (Q,N)\n",
    "    Kp = gaussian_kernel_matrix(query_parents, B=parent_data, bandwidth=bandwidth_parent)\n",
    "\n",
    "    # K(target): (Q,N)\n",
    "    Ky = _kernel_target_matrix(target_data, query_targets, discrete=target_discrete, bandwidth=bandwidth_target)\n",
    "\n",
    "    numer = (Kp * Ky).sum(axis=1)\n",
    "    denom = Kp.sum(axis=1)\n",
    "    return numer / np.maximum(denom, eps)\n",
    "\n",
    "def causal_bootstrap_truncated_factorization(df, *, x_cols, y_col, x_parents, parents,\n",
    "                                             discrete_vars=None, bandwidth=1.0,\n",
    "                                             random_seed=0, eps=1e-12):\n",
    "    \"\"\"Truncated factorization causal bootstrap (Algorithm 3).\n",
    "\n",
    "    Returns dataframe with columns x_cols + [y_col], same number of rows as df.\n",
    "    \"\"\"\n",
    "    discrete_vars = set(discrete_vars or [])\n",
    "    N = len(df)\n",
    "    rng = np.random.default_rng(random_seed)\n",
    "\n",
    "    y = df[y_col].to_numpy()\n",
    "    y_vals = np.unique(y)\n",
    "\n",
    "    PX_data = df[x_parents].to_numpy(dtype=float)  # observational P(X)\n",
    "\n",
    "    out_rows = []\n",
    "    for y_star in y_vals:\n",
    "        n_star = int((y == y_star).sum())\n",
    "        if n_star == 0:\n",
    "            continue\n",
    "\n",
    "        # Query P(X) at each row's E values but with Y fixed to y_star\n",
    "        PX_query_df = df[x_parents].copy()\n",
    "        if y_col in x_parents:\n",
    "            PX_query_df[y_col] = y_star\n",
    "        PX_query = PX_query_df.to_numpy(dtype=float)\n",
    "\n",
    "        phat_PX = _phat_joint(PX_query, PX_data, bandwidth=bandwidth, eps=eps)  # (N,)\n",
    "\n",
    "        # Product over v in E = P(X) \\ {Y}\n",
    "        prod = np.ones(N, dtype=float)\n",
    "        for v in [vv for vv in x_parents if vv != y_col]:\n",
    "            Pv = parents.get(v, [])\n",
    "            v_data = df[v].to_numpy()\n",
    "            if len(Pv) == 0:\n",
    "                # marginal p(v_i)\n",
    "                v_mat = _ensure_2d(v_data.astype(float))\n",
    "                phat_v = _phat_joint(v_mat, v_mat, bandwidth=bandwidth, eps=eps)\n",
    "            else:\n",
    "                parent_query_df = df[Pv].copy()\n",
    "                if y_col in Pv:\n",
    "                    parent_query_df[y_col] = y_star\n",
    "                parent_query = parent_query_df.to_numpy(dtype=float)\n",
    "\n",
    "                parent_data = df[Pv].to_numpy(dtype=float)  # observational parent data\n",
    "                phat_v = _phat_conditional(\n",
    "                    target_data=v_data,\n",
    "                    parent_data=parent_data,\n",
    "                    query_targets=v_data,           # v_i for each i\n",
    "                    query_parents=parent_query,     # parents_i with Y=y_star if applicable\n",
    "                    target_discrete=(v in discrete_vars),\n",
    "                    bandwidth_parent=bandwidth,\n",
    "                    bandwidth_target=bandwidth,\n",
    "                    eps=eps\n",
    "                )\n",
    "            prod *= np.maximum(phat_v, eps)\n",
    "\n",
    "        w_bar = prod / np.maximum(phat_PX, eps)\n",
    "\n",
    "        # If Y is in P(X), include K[y_i - y*]\n",
    "        Ky = kernel_y_vector(y, y_star, discrete=(y_col in discrete_vars))\n",
    "        w = (Ky * w_bar) / float(N)\n",
    "\n",
    "        w_sum = w.sum()\n",
    "        if w_sum <= 0:\n",
    "            continue\n",
    "        p = w / w_sum\n",
    "        idx = rng.choice(np.arange(N), size=n_star, replace=True, p=p)\n",
    "\n",
    "        block = df.iloc[idx][x_cols].copy()\n",
    "        block[y_col] = y_star\n",
    "        out_rows.append(block)\n",
    "\n",
    "    df_star = pd.concat(out_rows, ignore_index=True)\n",
    "    if len(df_star) != N:\n",
    "        df_star = df_star.sample(n=N, replace=True, random_state=random_seed).reset_index(drop=True)\n",
    "    return df_star\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0940c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tf = causal_bootstrap_truncated_factorization(\n",
    "    df,\n",
    "    x_cols=x_cols,\n",
    "    y_col=y_col,\n",
    "    x_parents=x_parents,\n",
    "    parents=parents,\n",
    "    discrete_vars=discrete_vars,\n",
    "    bandwidth=bandwidth,\n",
    "    random_seed=random_seed,\n",
    ")\n",
    "\n",
    "df_tf.head(), df_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d016f979",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = \"heart_disease_preprocessed_truncated_factorization_BOOTSTRAPPED.csv\"\n",
    "df_tf.to_csv(out_path, index=False)\n",
    "out_path"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
