{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a19161c3",
   "metadata": {},
   "source": [
    "\n",
    "## What is a Truncated Factorisation Causal Bootstrap Algorithm?\n",
    "\n",
    "- It is an algorithm which resamples the dataset to create a new dataset using the **truncated factorisation** of a causal graph.\n",
    "- The idea comes from Pearl’s **do-calculus** and the **g-formula**.\n",
    "- Instead of conditioning on mediators (front door) or confounders (back door) alone, it uses the **entire causal structure**.\n",
    "- The joint distribution of all variables is factorised according to the causal graph.\n",
    "- To simulate an intervention `do(X = x)`, we **truncate** (remove) the conditional distribution of `X` given its parents.\n",
    "- All other variables are resampled from their conditional distributions given their parents.\n",
    "- This allows us to estimate causal effects even in complex systems with:\n",
    "  - multiple confounders,\n",
    "  - mediators,\n",
    "  - chains of causes.\n",
    "- The key requirement is that the **causal graph is correctly specified** and all parent variables are observed.\n",
    "\n",
    "\n",
    "## Example\n",
    "\n",
    "Imagine you want to assess whether a new teaching method (the “cause” **X**) improves exam performance (the “effect” **Y**).\n",
    "\n",
    "- There are multiple observed variables:\n",
    "  - prior grades,\n",
    "  - motivation,\n",
    "  - study hours,\n",
    "  - practice problems.\n",
    "- Some of these variables affect both the teaching method assignment and exam performance.\n",
    "- Others lie on causal paths between **X** and **Y**.\n",
    "\n",
    "Causal structure (simplified):\n",
    "\n",
    "- Prior Grades -> Teaching Method -> Study Hours -> Exam Performance\n",
    "- Motivation -> Study Hours\n",
    "\n",
    "\n",
    "- We assume all parent variables of each node are observed.\n",
    "- To estimate the causal effect of the teaching method:\n",
    "  - We **intervene** on **X** by fixing it to a chosen value.\n",
    "  - We remove the probability model `P(X | Parents(X))`.\n",
    "  - We resample all downstream variables using their conditional distributions.\n",
    "- By repeatedly resampling, we generate a bootstrapped dataset that reflects:\n",
    "  - “What exam performance would look like if everyone received the same teaching method.”\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04d9c539",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "def _ensure_2d(arr):\n",
    "    arr = np.asarray(arr)\n",
    "    if arr.ndim == 1:\n",
    "        arr = arr.reshape(-1, 1)\n",
    "    return arr\n",
    "\n",
    "def gaussian_kernel_matrix(A, B=None, bandwidth=1.0):\n",
    "    \"\"\"\n",
    "    Gaussian/RBF kernel matrix: K_ij = exp(-0.5 * ||a_i - b_j||^2 / h^2)\n",
    "    A: (n,d), B: (m,d)\n",
    "    \"\"\"\n",
    "    A = _ensure_2d(A)\n",
    "    if B is None:\n",
    "        B = A\n",
    "    else:\n",
    "        B = _ensure_2d(B)\n",
    "    dists = cdist(A, B, metric=\"euclidean\")\n",
    "    return np.exp(-0.5 * (dists / float(bandwidth)) ** 2)\n",
    "\n",
    "def kernel_y_vector(y_data, y_star, *, discrete=True, bandwidth_y=1.0):\n",
    "    \"\"\"\n",
    "    K[y_i - y*] used in the paper.\n",
    "    - discrete=True -> Kronecker delta (1 if equal else 0)\n",
    "    - discrete=False -> Gaussian kernel on (y_i - y*)\n",
    "    \"\"\"\n",
    "    y_data = np.asarray(y_data)\n",
    "    if discrete:\n",
    "        return (y_data == y_star).astype(float)\n",
    "    return np.exp(-0.5 * ((y_data - y_star) / float(bandwidth_y)) ** 2)\n",
    "\n",
    "def phat_y_given_S(y_data, S_data, y_star, *, discrete_y=True, bandwidth_S=1.0, bandwidth_y=1.0, eps=1e-12):\n",
    "    \"\"\"\n",
    "    Nonparametric estimate of p_hat(y* | S_i) for each i, using kernel regression:\n",
    "      p_hat(y*|S_i) = sum_j K_S(S_i, S_j) * K_Y(y_j, y*) / sum_j K_S(S_i, S_j)\n",
    "    Returns: (N,) vector over i.\n",
    "    \"\"\"\n",
    "    K_S = gaussian_kernel_matrix(S_data, bandwidth=bandwidth_S)  # (N,N)\n",
    "    K_Y = kernel_y_vector(y_data, y_star, discrete=discrete_y, bandwidth_y=bandwidth_y)  # (N,)\n",
    "    numer = K_S @ K_Y\n",
    "    denom = K_S.sum(axis=1)\n",
    "    return numer / np.maximum(denom, eps)\n",
    "\n",
    "def phat_z_given_y(z_data, y_data, *, bandwidth_z=1.0, eps=1e-12):\n",
    "    \"\"\"\n",
    "    For front-door (Algorithm 2): estimate p_hat(z_i | y=v) for all i and each discrete y=v.\n",
    "    KDE on z within each y-group:\n",
    "      p_hat(z_i | y=v) ∝ (1/N_v) * sum_{j:y_j=v} K_z(z_i, z_j)\n",
    "    Returns: dict mapping y_value -> (N,) vector, entry i is p_hat(z_i | y_value)\n",
    "    \"\"\"\n",
    "    z = _ensure_2d(z_data)\n",
    "    y = np.asarray(y_data)\n",
    "    y_vals = np.unique(y)\n",
    "\n",
    "    Kzz = gaussian_kernel_matrix(z, bandwidth=bandwidth_z)  # (N,N)\n",
    "    phat = {}\n",
    "    for v in y_vals:\n",
    "        mask = (y == v)\n",
    "        Nv = int(mask.sum())\n",
    "        if Nv == 0:\n",
    "            phat[v] = np.full(len(y), eps)\n",
    "            continue\n",
    "        numer = Kzz[:, mask].sum(axis=1) / float(Nv)\n",
    "        phat[v] = np.maximum(numer, eps)\n",
    "    return phat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec710709",
   "metadata": {},
   "source": [
    "## Provide the causal graph inputs\n",
    "\n",
    "You must specify:\n",
    "\n",
    "- `y_col`: intervention variable **Y** (usually your target label)\n",
    "- `x_cols`: features **X** you want to sample (used only for output; the weighting uses `x_parents`)\n",
    "- `x_parents`: the parent set **P(X)** used in the truncated factorization formula (a list of column names).\n",
    "  - **Important:** include `y_col` in `x_parents` if Y is a parent of X in your graph.\n",
    "- `parents`: a dictionary mapping each variable name `v` in `E` to its parent list `P(v)` (may include `y_col`).\n",
    "\n",
    "Assumptions:\n",
    "- Variables are treated as continuous for kernels unless included in `discrete_vars`.\n",
    "- This is a *nonparametric* estimator intended to mirror the paper's RKHS/KDE simplification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2568fae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_col: heartdiseasepresence\n",
      "x_parents: ['heartdiseasepresence', 'age', 'sex_Female', 'sex_Male']\n",
      "E_vars: ['age', 'sex_Female', 'sex_Male']\n",
      "parents(v): {'age': [], 'sex_Female': [], 'sex_Male': []}\n",
      "N: 272\n"
     ]
    }
   ],
   "source": [
    "# --- USER INPUTS ---\n",
    "df = pd.read_csv(\"heart_disease_preprocessed.csv\")  # change if needed\n",
    "\n",
    "y_col = \"heartdiseasepresence\"\n",
    "\n",
    "# Example (EDIT to match your causal DAG):\n",
    "# Suppose the feature block X depends on Y and some observed covariates E.\n",
    "x_cols = [c for c in df.columns if c != y_col]\n",
    "\n",
    "# Parents of the (vector) feature block X in your DAG:\n",
    "x_parents = [y_col, \"age\", \"sex_Female\", \"sex_Male\"]  # EDIT: P(X) in your graph\n",
    "\n",
    "# E = P(X) \\ {Y}:\n",
    "E_vars = [v for v in x_parents if v != y_col]\n",
    "\n",
    "# Parent sets for each v in E (EDIT to match your graph).\n",
    "# If a v has no parents, use [].\n",
    "parents = {\n",
    "    \"age\": [],\n",
    "    \"sex_Female\": [],\n",
    "    \"sex_Male\": [],\n",
    "}\n",
    "\n",
    "# Kernel settings\n",
    "discrete_vars = {y_col, \"sex_Female\", \"sex_Male\"}  # treat these with Kronecker delta\n",
    "bandwidth = 1.0  # shared bandwidth for continuous kernels\n",
    "\n",
    "random_seed = 0\n",
    "\n",
    "print(\"y_col:\", y_col)\n",
    "print(\"x_parents:\", x_parents)\n",
    "print(\"E_vars:\", E_vars)\n",
    "print(\"parents(v):\", parents)\n",
    "print(\"N:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "436f144e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _phat_joint(query, data, *, bandwidth=1.0, eps=1e-12):\n",
    "    \"\"\"Unnormalized KDE joint density at query points: p_hat(query) ∝ (1/N) sum_j K(query, data_j).\"\"\"\n",
    "    K = gaussian_kernel_matrix(query, B=data, bandwidth=bandwidth)  # (Q,N)\n",
    "    return np.maximum(K.mean(axis=1), eps)\n",
    "\n",
    "def _kernel_target_matrix(target_data, query_targets, *, discrete=False, bandwidth=1.0):\n",
    "    \"\"\"Matrix Ky[q,j] = K(query_targets[q] - target_data[j]).\"\"\"\n",
    "    target_data = np.asarray(target_data)\n",
    "    qt = np.asarray(query_targets)\n",
    "    if qt.ndim == 0:\n",
    "        qt = qt.reshape(1)\n",
    "    if discrete:\n",
    "        return (qt[:, None] == target_data[None, :]).astype(float)\n",
    "    return np.exp(-0.5 * ((qt[:, None] - target_data[None, :]) / float(bandwidth)) ** 2)\n",
    "\n",
    "def _phat_conditional(target_data, parent_data, *, query_targets, query_parents,\n",
    "                      target_discrete=False, bandwidth_parent=1.0, bandwidth_target=1.0, eps=1e-12):\n",
    "    \"\"\"Kernel regression estimate of p_hat(target=query_targets | parents=query_parents).\n",
    "\n",
    "    Vectorized over Q queries (typically Q=N).\n",
    "    \"\"\"\n",
    "    parent_data = _ensure_2d(parent_data)\n",
    "    query_parents = _ensure_2d(query_parents)\n",
    "\n",
    "    # K(parents): (Q,N)\n",
    "    Kp = gaussian_kernel_matrix(query_parents, B=parent_data, bandwidth=bandwidth_parent)\n",
    "\n",
    "    # K(target): (Q,N)\n",
    "    Ky = _kernel_target_matrix(target_data, query_targets, discrete=target_discrete, bandwidth=bandwidth_target)\n",
    "\n",
    "    numer = (Kp * Ky).sum(axis=1)\n",
    "    denom = Kp.sum(axis=1)\n",
    "    return numer / np.maximum(denom, eps)\n",
    "\n",
    "def causal_bootstrap_truncated_factorization(df, *, x_cols, y_col, x_parents, parents,\n",
    "                                             discrete_vars=None, bandwidth=1.0,\n",
    "                                             random_seed=0, eps=1e-12):\n",
    "    \"\"\"Truncated factorization causal bootstrap (Algorithm 3).\n",
    "\n",
    "    Returns dataframe with columns x_cols + [y_col], same number of rows as df.\n",
    "    \"\"\"\n",
    "    discrete_vars = set(discrete_vars or [])\n",
    "    N = len(df)\n",
    "    rng = np.random.default_rng(random_seed)\n",
    "\n",
    "    y = df[y_col].to_numpy()\n",
    "    y_vals = np.unique(y)\n",
    "\n",
    "    PX_data = df[x_parents].to_numpy(dtype=float)  # observational P(X)\n",
    "\n",
    "    out_rows = []\n",
    "    for y_star in y_vals:\n",
    "        n_star = int((y == y_star).sum())\n",
    "        if n_star == 0:\n",
    "            continue\n",
    "\n",
    "        # Query P(X) at each row's E values but with Y fixed to y_star\n",
    "        PX_query_df = df[x_parents].copy()\n",
    "        if y_col in x_parents:\n",
    "            PX_query_df[y_col] = y_star\n",
    "        PX_query = PX_query_df.to_numpy(dtype=float)\n",
    "\n",
    "        phat_PX = _phat_joint(PX_query, PX_data, bandwidth=bandwidth, eps=eps)  # (N,)\n",
    "\n",
    "        # Product over v in E = P(X) \\ {Y}\n",
    "        prod = np.ones(N, dtype=float)\n",
    "        for v in [vv for vv in x_parents if vv != y_col]:\n",
    "            Pv = parents.get(v, [])\n",
    "            v_data = df[v].to_numpy()\n",
    "            if len(Pv) == 0:\n",
    "                # marginal p(v_i)\n",
    "                v_mat = _ensure_2d(v_data.astype(float))\n",
    "                phat_v = _phat_joint(v_mat, v_mat, bandwidth=bandwidth, eps=eps)\n",
    "            else:\n",
    "                parent_query_df = df[Pv].copy()\n",
    "                if y_col in Pv:\n",
    "                    parent_query_df[y_col] = y_star\n",
    "                parent_query = parent_query_df.to_numpy(dtype=float)\n",
    "\n",
    "                parent_data = df[Pv].to_numpy(dtype=float)  # observational parent data\n",
    "                phat_v = _phat_conditional(\n",
    "                    target_data=v_data,\n",
    "                    parent_data=parent_data,\n",
    "                    query_targets=v_data,           # v_i for each i\n",
    "                    query_parents=parent_query,     # parents_i with Y=y_star if applicable\n",
    "                    target_discrete=(v in discrete_vars),\n",
    "                    bandwidth_parent=bandwidth,\n",
    "                    bandwidth_target=bandwidth,\n",
    "                    eps=eps\n",
    "                )\n",
    "            prod *= np.maximum(phat_v, eps)\n",
    "\n",
    "        w_bar = prod / np.maximum(phat_PX, eps)\n",
    "\n",
    "        # If Y is in P(X), include K[y_i - y*]\n",
    "        Ky = kernel_y_vector(y, y_star, discrete=(y_col in discrete_vars))\n",
    "        w = (Ky * w_bar) / float(N)\n",
    "\n",
    "        w_sum = w.sum()\n",
    "        if w_sum <= 0:\n",
    "            continue\n",
    "        p = w / w_sum\n",
    "        idx = rng.choice(np.arange(N), size=n_star, replace=True, p=p)\n",
    "\n",
    "        block = df.iloc[idx][x_cols].copy()\n",
    "        block[y_col] = y_star\n",
    "        out_rows.append(block)\n",
    "\n",
    "    df_star = pd.concat(out_rows, ignore_index=True)\n",
    "    if len(df_star) != N:\n",
    "        df_star = df_star.sample(n=N, replace=True, random_state=random_seed).reset_index(drop=True)\n",
    "    return df_star\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0940c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(272, 26)\n"
     ]
    }
   ],
   "source": [
    "df_tf = causal_bootstrap_truncated_factorization(\n",
    "    df,\n",
    "    x_cols=x_cols,\n",
    "    y_col=y_col,\n",
    "    x_parents=x_parents,\n",
    "    parents=parents,\n",
    "    discrete_vars=discrete_vars,\n",
    "    bandwidth=bandwidth,\n",
    "    random_seed=random_seed,\n",
    ")\n",
    "\n",
    "print(df_tf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0bb86ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>thalach</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>ca</th>\n",
       "      <th>sex_Female</th>\n",
       "      <th>sex_Male</th>\n",
       "      <th>cp_Asymptomatic</th>\n",
       "      <th>cp_AtypicalAngina</th>\n",
       "      <th>...</th>\n",
       "      <th>restecg_STTAbnormality</th>\n",
       "      <th>exang_NoExAngina</th>\n",
       "      <th>exang_YesExAngina</th>\n",
       "      <th>slope_Downsloping</th>\n",
       "      <th>slope_Flat</th>\n",
       "      <th>slope_Upsloping</th>\n",
       "      <th>thal_FixedDefect</th>\n",
       "      <th>thal_Normal</th>\n",
       "      <th>thal_ReversibleDefect</th>\n",
       "      <th>heartdiseasepresence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.620934</td>\n",
       "      <td>1.593663</td>\n",
       "      <td>-0.268836</td>\n",
       "      <td>-0.772723</td>\n",
       "      <td>-0.928120</td>\n",
       "      <td>0.348460</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.729325</td>\n",
       "      <td>0.460243</td>\n",
       "      <td>1.494882</td>\n",
       "      <td>1.411306</td>\n",
       "      <td>-1.111053</td>\n",
       "      <td>-0.740979</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.280831</td>\n",
       "      <td>0.460243</td>\n",
       "      <td>-1.120286</td>\n",
       "      <td>-0.044713</td>\n",
       "      <td>-0.465247</td>\n",
       "      <td>-0.740979</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.505975</td>\n",
       "      <td>-0.106466</td>\n",
       "      <td>-0.877014</td>\n",
       "      <td>0.983065</td>\n",
       "      <td>0.569273</td>\n",
       "      <td>-0.740979</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.394299</td>\n",
       "      <td>-0.673176</td>\n",
       "      <td>0.967794</td>\n",
       "      <td>0.554824</td>\n",
       "      <td>-1.111053</td>\n",
       "      <td>-0.740979</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>0.057480</td>\n",
       "      <td>0.006876</td>\n",
       "      <td>2.143605</td>\n",
       "      <td>-0.729899</td>\n",
       "      <td>0.402268</td>\n",
       "      <td>0.348460</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>0.057480</td>\n",
       "      <td>0.460243</td>\n",
       "      <td>-0.613470</td>\n",
       "      <td>-1.629205</td>\n",
       "      <td>2.510884</td>\n",
       "      <td>-0.740979</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>1.397584</td>\n",
       "      <td>1.593663</td>\n",
       "      <td>0.785340</td>\n",
       "      <td>-1.757678</td>\n",
       "      <td>0.647625</td>\n",
       "      <td>2.527338</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>-0.612572</td>\n",
       "      <td>-0.786518</td>\n",
       "      <td>-1.992008</td>\n",
       "      <td>-0.986844</td>\n",
       "      <td>0.017112</td>\n",
       "      <td>2.527338</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>0.504181</td>\n",
       "      <td>-0.333150</td>\n",
       "      <td>-0.593198</td>\n",
       "      <td>-0.644251</td>\n",
       "      <td>1.121434</td>\n",
       "      <td>0.348460</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>272 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          age  trestbps      chol   thalach   oldpeak        ca  sex_Female  \\\n",
       "0    1.620934  1.593663 -0.268836 -0.772723 -0.928120  0.348460           0   \n",
       "1   -1.729325  0.460243  1.494882  1.411306 -1.111053 -0.740979           0   \n",
       "2    0.280831  0.460243 -1.120286 -0.044713 -0.465247 -0.740979           0   \n",
       "3   -1.505975 -0.106466 -0.877014  0.983065  0.569273 -0.740979           1   \n",
       "4   -1.394299 -0.673176  0.967794  0.554824 -1.111053 -0.740979           0   \n",
       "..        ...       ...       ...       ...       ...       ...         ...   \n",
       "267  0.057480  0.006876  2.143605 -0.729899  0.402268  0.348460           0   \n",
       "268  0.057480  0.460243 -0.613470 -1.629205  2.510884 -0.740979           0   \n",
       "269  1.397584  1.593663  0.785340 -1.757678  0.647625  2.527338           0   \n",
       "270 -0.612572 -0.786518 -1.992008 -0.986844  0.017112  2.527338           0   \n",
       "271  0.504181 -0.333150 -0.593198 -0.644251  1.121434  0.348460           0   \n",
       "\n",
       "     sex_Male  cp_Asymptomatic  cp_AtypicalAngina  ...  \\\n",
       "0           1                0                  0  ...   \n",
       "1           1                0                  0  ...   \n",
       "2           1                1                  0  ...   \n",
       "3           0                0                  1  ...   \n",
       "4           1                0                  1  ...   \n",
       "..        ...              ...                ...  ...   \n",
       "267         1                1                  0  ...   \n",
       "268         1                1                  0  ...   \n",
       "269         1                1                  0  ...   \n",
       "270         1                0                  0  ...   \n",
       "271         1                0                  0  ...   \n",
       "\n",
       "     restecg_STTAbnormality  exang_NoExAngina  exang_YesExAngina  \\\n",
       "0                         0                 1                  0   \n",
       "1                         0                 1                  0   \n",
       "2                         0                 1                  0   \n",
       "3                         0                 1                  0   \n",
       "4                         0                 1                  0   \n",
       "..                      ...               ...                ...   \n",
       "267                       0                 0                  1   \n",
       "268                       0                 0                  1   \n",
       "269                       0                 0                  1   \n",
       "270                       0                 1                  0   \n",
       "271                       0                 1                  0   \n",
       "\n",
       "     slope_Downsloping  slope_Flat  slope_Upsloping  thal_FixedDefect  \\\n",
       "0                    0           1                0                 0   \n",
       "1                    0           0                1                 0   \n",
       "2                    0           1                0                 1   \n",
       "3                    0           0                1                 0   \n",
       "4                    0           0                1                 0   \n",
       "..                 ...         ...              ...               ...   \n",
       "267                  0           1                0                 0   \n",
       "268                  1           0                0                 0   \n",
       "269                  0           1                0                 0   \n",
       "270                  0           0                1                 0   \n",
       "271                  0           1                0                 1   \n",
       "\n",
       "     thal_Normal  thal_ReversibleDefect  heartdiseasepresence  \n",
       "0              1                      0                     0  \n",
       "1              1                      0                     0  \n",
       "2              0                      0                     0  \n",
       "3              1                      0                     0  \n",
       "4              1                      0                     0  \n",
       "..           ...                    ...                   ...  \n",
       "267            0                      1                     1  \n",
       "268            0                      1                     1  \n",
       "269            1                      0                     1  \n",
       "270            1                      0                     1  \n",
       "271            0                      0                     1  \n",
       "\n",
       "[272 rows x 26 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d016f979",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = \"heart_disease_preprocessed_tf.csv\"\n",
    "df_tf.to_csv(out_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
