{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "203ede94",
   "metadata": {},
   "source": [
    "## What is a FrontDoor Causal Bootstrap Algorithm?\n",
    "\n",
    "- It is an algorithm which resamples the dataset to create a new dataset using the frontdoor criterion\n",
    "- The idea here is that a problem won't have only a single confounder but multiple instead\n",
    "- which therefore may not be observable\n",
    "- which is why we look at variables which sit on a causal path X -> Z -> Y known as **mediators**\n",
    "- the front door criterion applies where you have a known mediator Z which is observed and there are no  confounders associating X -> Z and Z -> Y\n",
    "\n",
    "**Example**\n",
    "- Imagine you want to assess whether studying more hours (the “cause” X) leads to improved exam performance (the “effect” Y). \n",
    "- However there are many unobserved confounders such as \"prior knowledge\" and \"innate ability\" which\n",
    "may not be observed so backdoor causal bootstrapping isn't possible\n",
    "- However lets say we have a known variable \"amount of practice problems done\"\n",
    "- we know that people who study more do more practice problems and people who do more practice problems get better grades\n",
    "- and if we know there are no variables which influence both studying more and doing more practice problems\n",
    "- and we also know there are no variables which influence both doing more practice problems and doing better in exams\n",
    "- then we can apply front door causal bootstrapping to really understand the relation between the input and output variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b102a5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>thalach</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>ca</th>\n",
       "      <th>sex_Female</th>\n",
       "      <th>sex_Male</th>\n",
       "      <th>cp_Asymptomatic</th>\n",
       "      <th>cp_AtypicalAngina</th>\n",
       "      <th>...</th>\n",
       "      <th>restecg_STTAbnormality</th>\n",
       "      <th>exang_NoExAngina</th>\n",
       "      <th>exang_YesExAngina</th>\n",
       "      <th>slope_Downsloping</th>\n",
       "      <th>slope_Flat</th>\n",
       "      <th>slope_Upsloping</th>\n",
       "      <th>thal_FixedDefect</th>\n",
       "      <th>thal_Normal</th>\n",
       "      <th>thal_ReversibleDefect</th>\n",
       "      <th>heartdiseasepresence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.950883</td>\n",
       "      <td>0.743598</td>\n",
       "      <td>-0.289108</td>\n",
       "      <td>0.040935</td>\n",
       "      <td>1.180495</td>\n",
       "      <td>-0.740979</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.397584</td>\n",
       "      <td>1.593663</td>\n",
       "      <td>0.785340</td>\n",
       "      <td>-1.757678</td>\n",
       "      <td>0.647625</td>\n",
       "      <td>2.527338</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.397584</td>\n",
       "      <td>-0.673176</td>\n",
       "      <td>-0.370199</td>\n",
       "      <td>-0.858371</td>\n",
       "      <td>1.347500</td>\n",
       "      <td>1.437899</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.952676</td>\n",
       "      <td>-0.106466</td>\n",
       "      <td>0.055526</td>\n",
       "      <td>1.625427</td>\n",
       "      <td>1.775790</td>\n",
       "      <td>-0.740979</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.505975</td>\n",
       "      <td>-0.106466</td>\n",
       "      <td>-0.877014</td>\n",
       "      <td>0.983065</td>\n",
       "      <td>0.569273</td>\n",
       "      <td>-0.740979</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  trestbps      chol   thalach   oldpeak        ca  sex_Female  \\\n",
       "0  0.950883  0.743598 -0.289108  0.040935  1.180495 -0.740979           0   \n",
       "1  1.397584  1.593663  0.785340 -1.757678  0.647625  2.527338           0   \n",
       "2  1.397584 -0.673176 -0.370199 -0.858371  1.347500  1.437899           0   \n",
       "3 -1.952676 -0.106466  0.055526  1.625427  1.775790 -0.740979           0   \n",
       "4 -1.505975 -0.106466 -0.877014  0.983065  0.569273 -0.740979           1   \n",
       "\n",
       "   sex_Male  cp_Asymptomatic  cp_AtypicalAngina  ...  restecg_STTAbnormality  \\\n",
       "0         1                0                  0  ...                       0   \n",
       "1         1                1                  0  ...                       0   \n",
       "2         1                1                  0  ...                       0   \n",
       "3         1                0                  0  ...                       0   \n",
       "4         0                0                  1  ...                       0   \n",
       "\n",
       "   exang_NoExAngina  exang_YesExAngina  slope_Downsloping  slope_Flat  \\\n",
       "0                 1                  0                  1           0   \n",
       "1                 0                  1                  0           1   \n",
       "2                 0                  1                  0           1   \n",
       "3                 1                  0                  1           0   \n",
       "4                 1                  0                  0           0   \n",
       "\n",
       "   slope_Upsloping  thal_FixedDefect  thal_Normal  thal_ReversibleDefect  \\\n",
       "0                0                 1            0                      0   \n",
       "1                0                 0            1                      0   \n",
       "2                0                 0            0                      1   \n",
       "3                0                 0            1                      0   \n",
       "4                1                 0            1                      0   \n",
       "\n",
       "   heartdiseasepresence  \n",
       "0                     0  \n",
       "1                     1  \n",
       "2                     1  \n",
       "3                     0  \n",
       "4                     0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "df = pd.read_csv('heart_disease_preprocessed.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84f3c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y (effect variable): heartdiseasepresence\n",
      "S (front-door/mediator set): ['thalach', 'oldpeak', 'slope_Downsloping', 'slope_Flat', 'slope_Upsloping', 'cp_Asymptomatic', 'cp_AtypicalAngina', 'cp_NonAnginalPain', 'cp_TypicalAngina']\n",
      "X (cause variables): ['age', 'trestbps', 'chol', 'ca', 'sex_Female', 'sex_Male', 'fbs_<=120', 'fbs_>120', 'restecg_LVHypertrophy', 'restecg_NormalECG', 'restecg_STTAbnormality', 'exang_NoExAngina', 'exang_YesExAngina', 'thal_FixedDefect', 'thal_Normal', 'thal_ReversibleDefect']\n"
     ]
    }
   ],
   "source": [
    "mediators = ['thalach', 'oldpeak', 'slope_Downsloping', 'slope_Flat', 'slope_Upsloping', 'cp_Asymptomatic', 'cp_AtypicalAngina', 'cp_NonAnginalPain', 'cp_TypicalAngina']\n",
    "\n",
    "effect = 'heartdiseasepresence'  # binary/bounded exposure in your heart dataset\n",
    "\n",
    "causes = [c for c in df.columns if c not in mediators + [effect]]\n",
    "\n",
    "print('effect variable:', effect)\n",
    "print('front-door/mediator set:', mediators)\n",
    "print('cause variables:', causes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e399ebed",
   "metadata": {},
   "source": [
    "**important functions**\n",
    "\n",
    "- gaussian_kernel_matrix function is a kernel function applied to vectors made of the confounder values from the dataframe to measure similarity,\n",
    "which can influence the probability of an associated row occuring in the resampled dataset \n",
    "- ensure_2d is a function to ensure that a dataframe is converted to a 2D numpy array to therefore allow doing things like applying the previous gaussian kernel function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "432fedfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_kernel_matrix(A, B=None, bandwidth=1.0):\n",
    "    \"\"\"Return Gaussian kernel matrix K_ij = exp(-0.5 * ||a_i - b_j||^2 / h^2).\"\"\"\n",
    "    if B is None:\n",
    "        B = A\n",
    "    dists = cdist(A, B, metric='euclidean')\n",
    "    K = np.exp(-0.5 * (dists / bandwidth) ** 2)\n",
    "    return K\n",
    "\n",
    "def ensure_2d(df, cols):\n",
    "    return df[cols].to_numpy(dtype=float).reshape(len(df), -1) # e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efad575f",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(df) #number of samples\n",
    "y = df[effect].to_numpy() #converting target column to numpy array\n",
    "unique_y = np.unique(y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950b8130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(272, 9)\n",
      "(272, 10)\n"
     ]
    }
   ],
   "source": [
    "mediator_matrix = ensure_2d(df, mediators) # mediator columns as 2D array\n",
    "fd_dfs = [] # this will hold multiple dataframes\n",
    "bandwidth_Z = 1.0 # bandwidth for kernel on (Z, Y)\n",
    "mediator_effect_matrix = np.hstack([mediator_matrix, y.reshape(-1, 1)])\n",
    "\n",
    "print(mediator_matrix.shape) # this is basically a subset of the df with the mediators in the form of a 2d array\n",
    "print(mediator_effect_matrix.shape) # this is a subset of the df with the mediators and effect variable in the form of a 2d array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e252225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.01412966, 0.05402431, ..., 0.06543395, 0.01972073,\n",
       "        0.00350431],\n",
       "       [0.01412966, 1.        , 0.52241715, ..., 0.20449579, 0.92771519,\n",
       "        0.00144345],\n",
       "       [0.05402431, 0.52241715, 1.        , ..., 0.81365915, 0.53448351,\n",
       "        0.00279739],\n",
       "       ...,\n",
       "       [0.06543395, 0.20449579, 0.81365915, ..., 1.        , 0.22205593,\n",
       "        0.00237703],\n",
       "       [0.01972073, 0.92771519, 0.53448351, ..., 0.22205593, 1.        ,\n",
       "        0.00481037],\n",
       "       [0.00350431, 0.00144345, 0.00279739, ..., 0.00237703, 0.00481037,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_mediators_effect = gaussian_kernel_matrix(mediator_effect_matrix, bandwidth=bandwidth_Z)\n",
    "kernel_mediators_effect # this essentially gives a matrix of similarity scores between all rows based on the mediators and effect variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa85e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(0)\n",
    "for y_star in unique_y:\n",
    "        # 1) we want to draw Z from p(z | do(y_star)) = p(z | y_star)\n",
    "        mask_y_star = (y == y_star) # boolean mask where y equals y_star\n",
    "        if mask_y_star.sum() == 0:\n",
    "            continue\n",
    "        # rows where y == y_star provide Z values\n",
    "        mediator_matrix_unique_effect = mediator_matrix[mask_y_star] # we get subset of matrix where y == y_star\n",
    "        # to make life simple we resample N times from those Z values uniformly\n",
    "        random_row_indexes = rng.choice(np.arange(mediator_matrix_unique_effect.shape[0]), size=N, replace=True) # randomly pick N indexes from the Z_pool\n",
    "        Z_draws = mediator_matrix_unique_effect[random_row_indexes] #this will be equivalent to the size of the original dataset\n",
    "\n",
    "        # 2) for each drawn (z, y_star), weight original rows by kernel on (Z, Y) to draw X\n",
    "        rows = []\n",
    "        for z_val in Z_draws:\n",
    "            # build query = (z_val, y_star) stack z_val and y_star horizontally\n",
    "            query = np.hstack([z_val, [y_star]])[None, :] \n",
    "            # kernel similarity to all original rows\n",
    "            K_q = np.exp(-0.5 * (cdist(query, mediator_effect_matrix, metric='euclidean') / bandwidth_Z) ** 2).ravel()\n",
    "            # for each original row, compute similarity to the query (z_val, y_star)\n",
    "            p = K_q / np.maximum(K_q.sum(), 1e-8)\n",
    "            # convert the similarities to probabilities\n",
    "            idx = rng.choice(np.arange(N), p=p)\n",
    "            # pick one row index based on these probabilities\n",
    "            row = df.iloc[[idx]].copy()\n",
    "            # add intervention info\n",
    "            row['do_' + effect] = y_star\n",
    "            # in the interventional world, Y is set to y_star\n",
    "            row[effect] = y_star\n",
    "            rows.append(row)\n",
    "        fd_df = pd.concat(rows, ignore_index=True)\n",
    "        fd_dfs.append(fd_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f919ce42",
   "metadata": {},
   "outputs": [],
   "source": [
    "if fd_dfs:\n",
    "    df_frontdoor = pd.concat(fd_dfs, ignore_index=True)\n",
    "else:\n",
    "    df_frontdoor = pd.DataFrame()\n",
    "\n",
    "df_frontdoor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
