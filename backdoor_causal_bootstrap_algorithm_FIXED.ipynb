{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc7053af",
   "metadata": {},
   "source": [
    "## What is a Backdoor Causal Bootstrap Algorithm?\n",
    "\n",
    "- It is an algorithm which resamples the dataset to create a new dataset\n",
    "- using the backdoor-criterion, which is satisfied if a variable Z is not a descendant of a 'cause' variable X and closes every back door path between a 'cause' X and 'effect' Y variable\n",
    "- these are known as **Confounders**\n",
    "- e.g. instead of X -> Y,   X <- Z -> Y (back door path)\n",
    "- so that ML models can learn causal relationships rather than just correlations\n",
    "\n",
    "**Example**\n",
    "- Imagine you want to assess whether drinking coffee (the “cause” X) leads to improved concentration at work (the “effect” Y). \n",
    "- But there’s a confounder: people who are sleep-deprived tend to drink more coffee and also tend to have worse concentration. \n",
    "- If you simply compare coffee drinkers vs non-drinkers, the effect of sleep-deprivation might bias your result. The back-door approach says: to get at the true effect of coffee on concentration, you need to adjust for (control for) the variable “sleep-deprivation” (call it Z) so that the path coffee ← sleep-deprivation → concentration is blocked. \n",
    "- After you control for how much sleep-deprivation someone has, you can compare coffee drinkers and non-drinkers on a “level playing field” of sleep-deprivation and infer more reliably how coffee itself affects concentration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c200660c",
   "metadata": {},
   "source": [
    "# Algorithm Intuition \n",
    "\n",
    "- wᵢ = K_Y(yᵢ, y*) / (N × p̂(y* | Sᵢ))\n",
    "- the idea is that the algorithm will put higher weight to samples which make confounders unlikely to predict target variable\n",
    "- which simulates deconfounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41409e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "def _ensure_2d(arr):\n",
    "    arr = np.asarray(arr)\n",
    "    if arr.ndim == 1:\n",
    "        arr = arr.reshape(-1, 1)\n",
    "    return arr\n",
    "\n",
    "# converts inputs into a 2d numpy array\n",
    "\n",
    "def gaussian_kernel_matrix(A, B=None, bandwidth=1.0):\n",
    "    \"\"\"\n",
    "    Gaussian/RBF kernel matrix: K_ij = exp(-0.5 * ||a_i - b_j||^2 / h^2)\n",
    "    A: (n,d), B: (m,d)\n",
    "    \"\"\"\n",
    "    A = _ensure_2d(A)\n",
    "    if B is None:\n",
    "        B = A\n",
    "    else:\n",
    "        B = _ensure_2d(B)\n",
    "    dists = cdist(A, B, metric=\"euclidean\")\n",
    "    return np.exp(-0.5 * (dists / float(bandwidth)) ** 2)\n",
    "\n",
    "# measures similarity of different rows based on Gaussian kernel\n",
    "\n",
    "def kernel_y_vector(y_data, y_star, *, discrete=True, bandwidth_y=1.0):\n",
    "    \"\"\"\n",
    "    K[y_i - y*] used in the paper.\n",
    "    - discrete=True -> Kronecker delta (1 if equal else 0)\n",
    "    - discrete=False -> Gaussian kernel on (y_i - y*)\n",
    "    \"\"\"\n",
    "    y_data = np.asarray(y_data)\n",
    "    if discrete:\n",
    "        return (y_data == y_star).astype(float)\n",
    "    return np.exp(-0.5 * ((y_data - y_star) / float(bandwidth_y)) ** 2)\n",
    "\n",
    "# creates a vector of similarity values between each y value and a unique y value\n",
    "\n",
    "def phat_y_given_S(y_data, S_data, y_star, *, discrete_y=True, bandwidth_S=1.0, bandwidth_y=1.0, eps=1e-12):\n",
    "    \"\"\"\n",
    "    Nonparametric estimate of p_hat(y* | S_i) for each i, using kernel regression:\n",
    "      p_hat(y*|S_i) = sum_j K_S(S_i, S_j) * K_Y(y_j, y*) / sum_j K_S(S_i, S_j)\n",
    "    Returns: (N,) vector over i.\n",
    "    \"\"\"\n",
    "    K_S = gaussian_kernel_matrix(S_data, bandwidth=bandwidth_S)  # (N,N)\n",
    "    K_Y = kernel_y_vector(y_data, y_star, discrete=discrete_y, bandwidth_y=bandwidth_y)  # (N,)\n",
    "    numer = K_S @ K_Y\n",
    "    denom = K_S.sum(axis=1)\n",
    "    return numer / np.maximum(denom, eps)\n",
    "\n",
    "# K_S is the similarity matrix for all confounder rows in the dataset\n",
    "# K_Y is the list of similarity scores of all y values to a unique y value\n",
    "# [[row1 sim to row1, row2 sim to row1, ...], [row1 sim to row2, row2 sim to row2, ...], ...] * [y1_sim to unique, y2_sim to unique, y3_sim to unique] = \n",
    "# (y1 sim to unique * [row1 sim to row1, row2 sim to row1, ...]) + (y2 sim to unique * [row1 sim to row2, row2 sim to row2, ...]) + ...\n",
    "# for each confounder row, we get a weighted sum of the similarity scores of all y values to the unique y value, weighted by how similar each confounder row is to the given confounder row\n",
    "# K_S.sum = [total sim score for confounder row1 to all rows, total sim score for confounder row2 to all rows, ...]\n",
    "# result = [total sim scores weighted by y similarities for row 1 / total sim score for confounder row 1, total sim scores weighted by y similarity for row 2 / total sim score for confounder row 2, ...]\n",
    "# amongst all confounder rows, given the similarity to confounder rows, how much proportion of those also have similar target variables\n",
    "# big score implies that amongst similar confounder rows, many also have similar target variables\n",
    "# low score implies that amongst similar confounder rows, few have similar target variables\n",
    "# return example is like [high score for confounder row 1, low score for confounder row 2, ...]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136b611f",
   "metadata": {},
   "source": [
    "## Choose columns\n",
    "\n",
    "- `y_col`: intervention / prediction target **Y**\n",
    "- `s_cols`: back-door admissible adjustment set **S** (measured confounders)\n",
    "- `x_cols`: features **X** used to train your model (typically exclude `s_cols` to avoid the model exploiting confounders)\n",
    "\n",
    "The code works for discrete **Y** (classification). For continuous **Y** (regression), set `discrete_y=False` and provide `bandwidth_y`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1cea5748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_col: heartdiseasepresence\n",
      "s_cols: ['age', 'sex_Female', 'sex_Male']\n",
      "x_cols: ['age', 'trestbps', 'chol', 'thalach', 'oldpeak', 'ca', 'sex_Female', 'sex_Male', 'cp_Asymptomatic', 'cp_AtypicalAngina', 'cp_NonAnginalPain', 'cp_TypicalAngina', 'fbs_<=120', 'fbs_>120', 'restecg_LVHypertrophy', 'restecg_NormalECG', 'restecg_STTAbnormality', 'exang_NoExAngina', 'exang_YesExAngina', 'slope_Downsloping', 'slope_Flat', 'slope_Upsloping', 'thal_FixedDefect', 'thal_Normal', 'thal_ReversibleDefect']\n",
      "N: 272\n"
     ]
    }
   ],
   "source": [
    "# --- USER INPUTS ---\n",
    "# Load your data:\n",
    "df = pd.read_csv(\"heart_disease_preprocessed.csv\")  # change if needed\n",
    "\n",
    "y_col = \"heartdiseasepresence\"\n",
    "s_cols = [c for c in [\"age\", \"sex_Female\", \"sex_Male\"] if c in df.columns]\n",
    "\n",
    "# By default, use all other columns except Y and S as X:\n",
    "x_cols = [c for c in df.columns if c not in [y_col]]\n",
    "\n",
    "# KDE / kernel settings\n",
    "discrete_y = True      # True for classification targets\n",
    "bandwidth_S = 1.0      # kernel bandwidth on S\n",
    "bandwidth_y = 1.0      # only used if discrete_y=False\n",
    "\n",
    "random_seed = 0\n",
    "\n",
    "print(\"y_col:\", y_col)\n",
    "print(\"s_cols:\", s_cols)\n",
    "print(\"x_cols:\", x_cols)\n",
    "print(\"N:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9748230c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def causal_bootstrap_backdoor(df, *, x_cols, y_col, s_cols,\n",
    "                              discrete_y=True, bandwidth_S=1.0, bandwidth_y=1.0,\n",
    "                              random_seed=0, eps=1e-12):\n",
    "    \"\"\"Back-door causal bootstrap (Algorithm 1).\n",
    "\n",
    "    Returns a dataframe with columns x_cols + [y_col] representing samples from p(x|do(y)).\n",
    "    Number of returned rows equals len(df).\n",
    "    \"\"\"\n",
    "    N = len(df)\n",
    "    y = df[y_col].to_numpy()\n",
    "    S = df[s_cols].to_numpy(dtype=float) if len(s_cols) else np.zeros((N, 0))\n",
    "\n",
    "    rng = np.random.default_rng(random_seed)\n",
    "\n",
    "    # discrete Y: group by y* and generate n_y* = count(y=y*) samples (preserves marginal p(y))\n",
    "    y_vals = np.unique(y) if discrete_y else y\n",
    "\n",
    "    out_rows = []\n",
    "    for y_star in y_vals:\n",
    "        if discrete_y:\n",
    "            n_star = int((y == y_star).sum())\n",
    "            if n_star == 0:\n",
    "                continue\n",
    "        else:\n",
    "            # regression: one sample per observed y value\n",
    "            n_star = 1\n",
    "\n",
    "        # p_hat(y* | S_i) for each i\n",
    "        phat = phat_y_given_S(y, S, y_star, discrete_y=discrete_y,\n",
    "                              bandwidth_S=bandwidth_S, bandwidth_y=bandwidth_y, eps=eps)\n",
    "\n",
    "        # K[y_i - y*]\n",
    "        Ky = kernel_y_vector(y, y_star, discrete=discrete_y, bandwidth_y=bandwidth_y)\n",
    "        # getting similarities of all y values in relation to the unique y value, identifying\n",
    "        # amongst all y values, how similar is each row to it to get a sense of number of similar y values to it\n",
    "\n",
    "        # weights: w_i = Ky / (N * phat)\n",
    "        w = Ky / (float(N) * np.maximum(phat, eps))\n",
    "        # w is a list of weights, where the highest weight is the highest y similarity over the lowest similarity of confounder rows with similar y values\n",
    "        # in other words, we will put more emphasis on rows where the confounder y values are similar but the actual confounder rows are dissimilar\n",
    "\n",
    "        # sample indices with prob proportional to w\n",
    "        w_sum = w.sum()\n",
    "        if w_sum <= 0:\n",
    "            continue\n",
    "        p = w / w_sum\n",
    "        idx = rng.choice(np.arange(N), size=n_star, replace=True, p=p)\n",
    "\n",
    "        block = df.iloc[idx][x_cols].copy()\n",
    "        block[y_col] = y_star\n",
    "        out_rows.append(block)\n",
    "\n",
    "    df_star = pd.concat(out_rows, ignore_index=True)\n",
    "\n",
    "    # sanity: ensure same size as original\n",
    "    if len(df_star) != N and discrete_y:\n",
    "        # fallback: if rounding/counting mismatch, resample to N\n",
    "        df_star = df_star.sample(n=N, replace=True, random_state=random_seed).reset_index(drop=True)\n",
    "\n",
    "    return df_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48800298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(272, 26)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_backdoor = causal_bootstrap_backdoor(\n",
    "    df,\n",
    "    x_cols=x_cols,\n",
    "    y_col=y_col,\n",
    "    s_cols=s_cols,\n",
    "    discrete_y=discrete_y,\n",
    "    bandwidth_S=bandwidth_S,\n",
    "    bandwidth_y=bandwidth_y,\n",
    "    random_seed=random_seed,\n",
    ")\n",
    "\n",
    "df_backdoor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dde05520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>thalach</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>ca</th>\n",
       "      <th>sex_Female</th>\n",
       "      <th>sex_Male</th>\n",
       "      <th>cp_Asymptomatic</th>\n",
       "      <th>cp_AtypicalAngina</th>\n",
       "      <th>...</th>\n",
       "      <th>restecg_STTAbnormality</th>\n",
       "      <th>exang_NoExAngina</th>\n",
       "      <th>exang_YesExAngina</th>\n",
       "      <th>slope_Downsloping</th>\n",
       "      <th>slope_Flat</th>\n",
       "      <th>slope_Upsloping</th>\n",
       "      <th>thal_FixedDefect</th>\n",
       "      <th>thal_Normal</th>\n",
       "      <th>thal_ReversibleDefect</th>\n",
       "      <th>heartdiseasepresence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.509259</td>\n",
       "      <td>-0.673176</td>\n",
       "      <td>-0.735106</td>\n",
       "      <td>-1.457909</td>\n",
       "      <td>0.647625</td>\n",
       "      <td>-0.740979</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.059273</td>\n",
       "      <td>-1.579912</td>\n",
       "      <td>-0.795924</td>\n",
       "      <td>-0.044713</td>\n",
       "      <td>1.549723</td>\n",
       "      <td>-0.740979</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.280831</td>\n",
       "      <td>0.460243</td>\n",
       "      <td>-1.120286</td>\n",
       "      <td>-0.044713</td>\n",
       "      <td>-0.465247</td>\n",
       "      <td>-0.740979</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.505975</td>\n",
       "      <td>-0.106466</td>\n",
       "      <td>-0.877014</td>\n",
       "      <td>0.983065</td>\n",
       "      <td>0.569273</td>\n",
       "      <td>-0.740979</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.394299</td>\n",
       "      <td>-0.673176</td>\n",
       "      <td>0.967794</td>\n",
       "      <td>0.554824</td>\n",
       "      <td>-1.111053</td>\n",
       "      <td>-0.740979</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>0.057480</td>\n",
       "      <td>0.006876</td>\n",
       "      <td>2.143605</td>\n",
       "      <td>-0.729899</td>\n",
       "      <td>0.402268</td>\n",
       "      <td>0.348460</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>0.057480</td>\n",
       "      <td>0.460243</td>\n",
       "      <td>-0.613470</td>\n",
       "      <td>-1.629205</td>\n",
       "      <td>2.510884</td>\n",
       "      <td>-0.740979</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>1.397584</td>\n",
       "      <td>1.593663</td>\n",
       "      <td>0.785340</td>\n",
       "      <td>-1.757678</td>\n",
       "      <td>0.647625</td>\n",
       "      <td>2.527338</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>-0.612572</td>\n",
       "      <td>-0.786518</td>\n",
       "      <td>-1.992008</td>\n",
       "      <td>-0.986844</td>\n",
       "      <td>0.017112</td>\n",
       "      <td>2.527338</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>-1.617650</td>\n",
       "      <td>1.140295</td>\n",
       "      <td>-0.491834</td>\n",
       "      <td>1.368482</td>\n",
       "      <td>-1.111053</td>\n",
       "      <td>-0.740979</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>272 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          age  trestbps      chol   thalach   oldpeak        ca  sex_Female  \\\n",
       "0    1.509259 -0.673176 -0.735106 -1.457909  0.647625 -0.740979           1   \n",
       "1   -1.059273 -1.579912 -0.795924 -0.044713  1.549723 -0.740979           0   \n",
       "2    0.280831  0.460243 -1.120286 -0.044713 -0.465247 -0.740979           0   \n",
       "3   -1.505975 -0.106466 -0.877014  0.983065  0.569273 -0.740979           1   \n",
       "4   -1.394299 -0.673176  0.967794  0.554824 -1.111053 -0.740979           0   \n",
       "..        ...       ...       ...       ...       ...       ...         ...   \n",
       "267  0.057480  0.006876  2.143605 -0.729899  0.402268  0.348460           0   \n",
       "268  0.057480  0.460243 -0.613470 -1.629205  2.510884 -0.740979           0   \n",
       "269  1.397584  1.593663  0.785340 -1.757678  0.647625  2.527338           0   \n",
       "270 -0.612572 -0.786518 -1.992008 -0.986844  0.017112  2.527338           0   \n",
       "271 -1.617650  1.140295 -0.491834  1.368482 -1.111053 -0.740979           0   \n",
       "\n",
       "     sex_Male  cp_Asymptomatic  cp_AtypicalAngina  ...  \\\n",
       "0           0                0                  0  ...   \n",
       "1           1                1                  0  ...   \n",
       "2           1                1                  0  ...   \n",
       "3           0                0                  1  ...   \n",
       "4           1                0                  1  ...   \n",
       "..        ...              ...                ...  ...   \n",
       "267         1                1                  0  ...   \n",
       "268         1                1                  0  ...   \n",
       "269         1                1                  0  ...   \n",
       "270         1                0                  0  ...   \n",
       "271         1                1                  0  ...   \n",
       "\n",
       "     restecg_STTAbnormality  exang_NoExAngina  exang_YesExAngina  \\\n",
       "0                         0                 1                  0   \n",
       "1                         0                 0                  1   \n",
       "2                         0                 1                  0   \n",
       "3                         0                 1                  0   \n",
       "4                         0                 1                  0   \n",
       "..                      ...               ...                ...   \n",
       "267                       0                 0                  1   \n",
       "268                       0                 0                  1   \n",
       "269                       0                 0                  1   \n",
       "270                       0                 1                  0   \n",
       "271                       0                 1                  0   \n",
       "\n",
       "     slope_Downsloping  slope_Flat  slope_Upsloping  thal_FixedDefect  \\\n",
       "0                    0           1                0                 0   \n",
       "1                    0           1                0                 0   \n",
       "2                    0           1                0                 1   \n",
       "3                    0           0                1                 0   \n",
       "4                    0           0                1                 0   \n",
       "..                 ...         ...              ...               ...   \n",
       "267                  0           1                0                 0   \n",
       "268                  1           0                0                 0   \n",
       "269                  0           1                0                 0   \n",
       "270                  0           0                1                 0   \n",
       "271                  0           0                1                 0   \n",
       "\n",
       "     thal_Normal  thal_ReversibleDefect  heartdiseasepresence  \n",
       "0              1                      0                     0  \n",
       "1              1                      0                     0  \n",
       "2              0                      0                     0  \n",
       "3              1                      0                     0  \n",
       "4              1                      0                     0  \n",
       "..           ...                    ...                   ...  \n",
       "267            0                      1                     1  \n",
       "268            0                      1                     1  \n",
       "269            1                      0                     1  \n",
       "270            1                      0                     1  \n",
       "271            0                      1                     1  \n",
       "\n",
       "[272 rows x 26 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_backdoor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ab28ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "out_path = \"heart_disease_preprocessed_backdoor.csv\"\n",
    "df_backdoor.to_csv(out_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
