{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c58bab3",
   "metadata": {},
   "source": [
    "## What is a FrontDoor Causal Bootstrap Algorithm?\n",
    "\n",
    "- It is an algorithm which resamples the dataset to create a new dataset using the frontdoor criterion\n",
    "- The idea here is that a problem won't have only a single confounder but multiple instead\n",
    "- which therefore may not be observable\n",
    "- which is why we look at variables which sit on a causal path X -> Z -> Y known as **mediators**\n",
    "- the front door criterion applies where you have a known mediator Z which is observed and there are no  confounders associating X -> Z and Z -> Y\n",
    "\n",
    "**Example**\n",
    "- Imagine you want to assess whether studying more hours (the “cause” X) leads to improved exam performance (the “effect” Y). \n",
    "- However there are many unobserved confounders such as \"prior knowledge\" and \"innate ability\" which\n",
    "may not be observed so backdoor causal bootstrapping isn't possible\n",
    "- However lets say we have a known variable \"amount of practice problems done\"\n",
    "- we know that people who study more do more practice problems and people who do more practice problems get better grades\n",
    "- and if we know there are no variables which influence both studying more and doing more practice problems\n",
    "- and we also know there are no variables which influence both doing more practice problems and doing better in exams\n",
    "- then we can apply front door causal bootstrapping to really understand the relation between the input and output variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "620761a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "def _ensure_2d(arr):\n",
    "    arr = np.asarray(arr)\n",
    "    if arr.ndim == 1:\n",
    "        arr = arr.reshape(-1, 1)\n",
    "    return arr\n",
    "\n",
    "def gaussian_kernel_matrix(A, B=None, bandwidth=1.0):\n",
    "    \"\"\"\n",
    "    Gaussian/RBF kernel matrix: K_ij = exp(-0.5 * ||a_i - b_j||^2 / h^2)\n",
    "    A: (n,d), B: (m,d)\n",
    "    \"\"\"\n",
    "    A = _ensure_2d(A)\n",
    "    if B is None:\n",
    "        B = A\n",
    "    else:\n",
    "        B = _ensure_2d(B)\n",
    "    dists = cdist(A, B, metric=\"euclidean\")\n",
    "    return np.exp(-0.5 * (dists / float(bandwidth)) ** 2)\n",
    "\n",
    "def kernel_y_vector(y_data, y_star, *, discrete=True, bandwidth_y=1.0):\n",
    "    \"\"\"\n",
    "    K[y_i - y*] used in the paper.\n",
    "    - discrete=True -> Kronecker delta (1 if equal else 0)\n",
    "    - discrete=False -> Gaussian kernel on (y_i - y*)\n",
    "    \"\"\"\n",
    "    y_data = np.asarray(y_data)\n",
    "    if discrete:\n",
    "        return (y_data == y_star).astype(float)\n",
    "    return np.exp(-0.5 * ((y_data - y_star) / float(bandwidth_y)) ** 2)\n",
    "\n",
    "def phat_y_given_S(y_data, S_data, y_star, *, discrete_y=True, bandwidth_S=1.0, bandwidth_y=1.0, eps=1e-12):\n",
    "    \"\"\"\n",
    "    Nonparametric estimate of p_hat(y* | S_i) for each i, using kernel regression:\n",
    "      p_hat(y*|S_i) = sum_j K_S(S_i, S_j) * K_Y(y_j, y*) / sum_j K_S(S_i, S_j)\n",
    "    Returns: (N,) vector over i.\n",
    "    \"\"\"\n",
    "    K_S = gaussian_kernel_matrix(S_data, bandwidth=bandwidth_S)  # (N,N)\n",
    "    K_Y = kernel_y_vector(y_data, y_star, discrete=discrete_y, bandwidth_y=bandwidth_y)  # (N,)\n",
    "    numer = K_S @ K_Y\n",
    "    denom = K_S.sum(axis=1)\n",
    "    return numer / np.maximum(denom, eps)\n",
    "\n",
    "def phat_z_given_y(z_data, y_data, *, bandwidth_z=1.0, eps=1e-12):\n",
    "    \"\"\"\n",
    "    For front-door (Algorithm 2): estimate p_hat(z_i | y=v) for all i and each discrete y=v.\n",
    "    KDE on z within each y-group:\n",
    "      p_hat(z_i | y=v) ∝ (1/N_v) * sum_{j:y_j=v} K_z(z_i, z_j)\n",
    "    Returns: dict mapping y_value -> (N,) vector, entry i is p_hat(z_i | y_value)\n",
    "    \"\"\"\n",
    "    z = _ensure_2d(z_data)\n",
    "    y = np.asarray(y_data)\n",
    "    y_vals = np.unique(y)\n",
    "\n",
    "    Kzz = gaussian_kernel_matrix(z, bandwidth=bandwidth_z)  # (N,N)\n",
    "    phat = {}\n",
    "    for v in y_vals:\n",
    "        mask = (y == v)\n",
    "        Nv = int(mask.sum())\n",
    "        if Nv == 0:\n",
    "            phat[v] = np.full(len(y), eps)\n",
    "            continue\n",
    "        numer = Kzz[:, mask].sum(axis=1) / float(Nv)\n",
    "        phat[v] = np.maximum(numer, eps)\n",
    "    return phat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0551f0d0",
   "metadata": {},
   "source": [
    "## Choose columns\n",
    "\n",
    "- `y_col`: intervention / prediction target **Y** (assumed *discrete* here, matching Algorithm 2)\n",
    "- `z_cols`: mediator(s) **Z**\n",
    "- `x_cols`: features **X** used to train your model (typically exclude Z so you learn the effect of Y on X, not the mediation variable itself)\n",
    "\n",
    "Kernel settings:\n",
    "- `bandwidth_z` controls KDE smoothness on mediator space.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5914c80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- USER INPUTS ---\n",
    "df = pd.read_csv(\"heart_disease_preprocessed.csv\")  # change if needed\n",
    "\n",
    "y_col = \"heartdiseasepresence\"\n",
    "z_cols = [\"ca\"]  # mediator(s) Z\n",
    "\n",
    "# Default X: everything except Y (keep mediators in output)\n",
    "x_cols = [c for c in df.columns if c != y_col]\n",
    "\n",
    "bandwidth_z = 1.0\n",
    "random_seed = 0\n",
    "\n",
    "print(\"y_col:\", y_col)\n",
    "print(\"z_cols:\", z_cols)\n",
    "print(\"x_cols:\", x_cols[:10], \"...\" if len(x_cols) > 10 else \"\")\n",
    "print(\"N:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31ef338",
   "metadata": {},
   "outputs": [],
   "source": [
    "def causal_bootstrap_frontdoor(df, *, x_cols, y_col, z_cols,\n",
    "                             bandwidth_z=1.0, random_seed=0, eps=1e-12):\n",
    "    \"\"\"Front-door causal bootstrap (Algorithm 2), discrete Y.\n",
    "\n",
    "    Returns dataframe with columns x_cols + [y_col], same number of rows as df.\n",
    "    \"\"\"\n",
    "    N = len(df)\n",
    "    y = df[y_col].to_numpy()\n",
    "    z = df[z_cols].to_numpy(dtype=float)\n",
    "\n",
    "    rng = np.random.default_rng(random_seed)\n",
    "    y_vals = np.unique(y)\n",
    "\n",
    "    # Precompute p_hat(z_i | y=v) for all v\n",
    "    phat_z = phat_z_given_y(z, y, bandwidth_z=bandwidth_z, eps=eps)\n",
    "\n",
    "    out_rows = []\n",
    "    for y_star in y_vals:\n",
    "        n_star = int((y == y_star).sum())\n",
    "        if n_star == 0:\n",
    "            continue\n",
    "\n",
    "        # weights for each i: p_hat(z_i|y_star) / (N * p_hat(z_i|y_i))\n",
    "        denom = np.array([phat_z[yi][i] for i, yi in enumerate(y)], dtype=float)\n",
    "        numer = phat_z[y_star]\n",
    "        w = numer / (float(N) * np.maximum(denom, eps))\n",
    "\n",
    "        w_sum = w.sum()\n",
    "        if w_sum <= 0:\n",
    "            continue\n",
    "        p = w / w_sum\n",
    "        idx = rng.choice(np.arange(N), size=n_star, replace=True, p=p)\n",
    "\n",
    "        block = df.iloc[idx][x_cols].copy()\n",
    "        block[y_col] = y_star\n",
    "        out_rows.append(block)\n",
    "\n",
    "    df_star = pd.concat(out_rows, ignore_index=True)\n",
    "    if len(df_star) != N:\n",
    "        df_star = df_star.sample(n=N, replace=True, random_state=random_seed).reset_index(drop=True)\n",
    "    return df_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9da3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_frontdoor = causal_bootstrap_frontdoor(\n",
    "    df,\n",
    "    x_cols=x_cols,\n",
    "    y_col=y_col,\n",
    "    z_cols=z_cols,\n",
    "    bandwidth_z=bandwidth_z,\n",
    "    random_seed=random_seed,\n",
    ")\n",
    "\n",
    "df_frontdoor.head(), df_frontdoor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebaa761a",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = \"heart_disease_preprocessed_frontdoor.csv\"\n",
    "df_frontdoor.to_csv(out_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
